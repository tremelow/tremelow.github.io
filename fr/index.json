[{"content":" Partage de maths sympa, entre autres ","date":null,"permalink":"https://tremelow.github.io/fr/blog/","section":"Articles de blog","summary":"","title":"Articles de blog"},{"content":"Au LML, nous avons débuté un groupe de travail autour des équations différentielles stochastiques (EDS). L\u0026rsquo;objectif est d\u0026rsquo;allier les aspects théoriques et pratiques, pour comprendre notamment l\u0026rsquo;équation de Langevin et les processus de diffusion génératifs.\nÀ cet effet, nous souhaitons principalement étudier deux références :\nUn cours de mathématiques d\u0026rsquo;introduction (théorique) aux EDS.\n[Evans], \u0026ldquo;An Introduction to Stochastic Differential Equations\u0026rdquo; (2013) Un cours axé sur les aspects pratiques de simulation et le lien avec l\u0026rsquo;apprentissage, avec des notebooks pour la programmation.\n[Wang], \u0026ldquo;Mathematical Foundation of Diffusion Generative Models\u0026rdquo; On espère faire une session toutes les deux semaines environ, sur quelques mois. Celles-ci se déroulent sur Zoom et sont enregistrées. L\u0026rsquo;accès aux enregistrements est soumis à un mot de passe, n\u0026rsquo;hésitez pas à me contacter pour les obtenir !\nSession 1 (2024-11-22) # Motivation : comment est-ce que les EDS apparaissent dans les processus génératifs ? Chapitre 1 de [Evans] : qu\u0026rsquo;est-ce qu\u0026rsquo;une EDS ? Qu\u0026rsquo;est-ce qui diffère des équations différentielles ordinaires ? Ressources : PDF Notes saisies pendant la session ipynb Notebook Python avec quelques simulations (à exécuter) REC Enregistrement de la session ","date":"22 novembre 2024","permalink":"https://tremelow.github.io/fr/blog/gdt-eds-lml/","section":"Articles de blog","summary":"","title":"Équations différentielles stochastiques et modèles de diffusion (groupe de travail)"},{"content":" leopold.tremant \u0026lt;at\u0026gt; univ-artois.fr\nDessin par Marie Morin\nMon CV\nJe suis un jeune enseignant-chercheur en analyse numérique à l\u0026rsquo;Université d\u0026rsquo;Artois, affilié à l\u0026rsquo;IUT de Lens et au Laboratoire de Mathématiques de Lens. Je m\u0026rsquo;intéresse à l\u0026rsquo;intégration en temps long, aux développements asymptotiques et à l\u0026rsquo;apprentissage profond.\n","date":null,"permalink":"https://tremelow.github.io/fr/","section":"Site personnel de Léopold Trémant","summary":"","title":"Site personnel de Léopold Trémant"},{"content":"Le cours R5.A.12 - Modélisation mathématique de 2024-2025 de l\u0026rsquo;IUT d\u0026rsquo;Informatique de Lens s\u0026rsquo;intéresse à l\u0026rsquo;apprentissage. L\u0026rsquo;objectif est d\u0026rsquo;introduire les outils mathématiques nécessaires à la bonne compréhension des bases de ces méthodes, à travers trois composantes :\nReprésentation : Un modèle qui peut être implémenté (l\u0026rsquo;architecture, le nombre de paramètres\u0026hellip;) ; Évaluation : Une loss, une fonction objectif ou de score ; Optimisation : Une manière efficace d\u0026rsquo;ajuster les paramètres. On ne considère que l\u0026rsquo;apprentissage supervisé, ce qui permet de se concentrer sur les parties 1 et 3. On commence par une représentation simple d\u0026rsquo;approximation affine et régression linéaire pour se concentrer sur l\u0026rsquo;optimisation. Une fois le pipeline d\u0026rsquo;optimisation en PyTorch est assimilé sur cet exemple, on introduit les perceptrons multi-couches, puis les transformeurs.\nLes aspects théoriques sont illustrés par des TPs, disponibles dans la liste suivante, fréquemment mise à jour.\nProjet 1 : Focus sur la partie Optimisation\nTP1.1 - Régression linéaire ipynb TP1.2 - Descente de gradient ipynb TP1.3 - Optimisation en PyTorch ipynb TP1.4 - Apprentissage par lots ipynb py Projet 2 : Perceptrons multi-couche utils.py TP2.1 - Régression sans a priori ipynb TP2.2 - Classification sur MNIST ipynb Les vidéos inaccessibles sur le réseau de l\u0026rsquo;IUT :\nDeepmath - Tenseurs ","date":"11 juin 2024","permalink":"https://tremelow.github.io/fr/blog/introduction_deep_learning/","section":"Articles de blog","summary":"","title":"Introduction au deep learning"},{"content":" Une vidéo est apparue qui discute d\u0026rsquo;un jeu très similaire à ce que j\u0026rsquo;avais proposé à des collégien-ne-s pour MATh.en.JEANS.\nLe jeu de MATh.en.JEANS #Le jeu était le suivant :\nÉmilie et Manon jouent à « pile ou face » (P ou F), mais au lieu de parier sur P ou F, elles parient chacune sur un motif. Émilie parie sur PFP et Manon sur PFF. Chaque fois que l\u0026rsquo;un de leurs motifs apparaît (avec chevauchement), la joueuse qui l\u0026rsquo;a choisie marque un point. Le jeu se termine lorsqu\u0026rsquo;une joueuse atteint 3 points.\nPar exemple, en indiquant le motif d\u0026rsquo;Émilie en italique et celui de Manon en gras, voici une partie aléatoire :\nPFPFFPFFFPPPFF\nIci, le jeu s\u0026rsquo;arrête car Manon gagne. Cependant, après avoir simulé un million de parties, il semble qu\u0026rsquo;Émilie gagne beaucoup plus souvent. Comment l\u0026rsquo;expliquer ?\nLe but n\u0026rsquo;était pas que j\u0026rsquo;apporte une solution à ce problème, je n\u0026rsquo;y ai donc pas trop réfléchi, mais les élèves l\u0026rsquo;ont trouvé amusant et stimulant. Ils n\u0026rsquo;ont pas réussi à le résoudre, même après un certain temps. Mon rôle était de pointer les potentielles failles dans leurs conjectures (par exemple « le motif d\u0026rsquo;Émilie peut avoir des chevauchements, pas celui de Manon »).\nLe jeu PP-PF #Dans la vidéo, l\u0026rsquo;idée de départ est la même : chaque joueur choisit un motif et les compte avec chevauchement. Sauf que les motifs sont plus courts et que le nombre de tours est fixe : les points sont comptés après 100 lancers. Qui gagne le plus entre PP et PF ?\nMihai Nica prend le temps de prouver que PF gagne plus, de combien, et comment le nombre de tours peut affecter le résultat. Bien que l\u0026rsquo;explication soit un peu technique pour des élèves du secondaire, les visualisations sont excellentes et je l\u0026rsquo;ai trouvée très intéressante ! Son code est également disponible dans un Google Colab en description.\nComment est-ce que ce travail pourrait servir de tremplin pour comparer PFF et PFP ?\n","date":"15 mai 2024","permalink":"https://tremelow.github.io/fr/blog/video-recommendations/2024-05-17-hh-vs-ht/","section":"Articles de blog","summary":"","title":"Mihai Nica - Alice HH vs Bob HT"},{"content":" Si vous vous baladez en ligne et que vous êtes intéressé-e par les maths, la programmation ou les jeux-vidéos, vous avez probablement vu passer le code d\u0026rsquo;« inverse de la racine carrée » de Quake III.\nfloat q_rsqrt(float number) { long i; float x2, y; const float threehalfs = 1.5F; x2 = number * 0.5F; y = number; i = * ( long * ) \u0026amp;y; // evil floating point bit level hacking i = 0x5f3759df - ( i \u0026gt;\u0026gt; 1 ); // what the fuck? y = * ( float * ) \u0026amp;i; y = y * ( threehalfs - ( x2 * y * y ) ); // 1st iteration // y = y * ( threehalfs - ( x2 * y * y ) ); // 2nd iteration, this can be removed return y; } Ce snippet est parfait : chaque ligne est complètement incompréhensible, les commentaires sont super descriptifs, et c\u0026rsquo;est du vrai code dans un vrai jeu. En 20 minutes, cette vidéo de Nemean l\u0026rsquo;explique en détail, en allant de l\u0026rsquo;implémentation des nombres flottants jusqu\u0026rsquo;à la justification mathématique de pourquoi ça marche (que je ne divulgâcherai pas).\n","date":"18 mars 2024","permalink":"https://tremelow.github.io/fr/blog/video-recommendations/2024-03-18-inverse-sqrt/","section":"Articles de blog","summary":"","title":"Nemean - Fast Inverse Square Root — A Quake III Algorithm"},{"content":" Cette semaine, je recommande cette vidéo de sudgylacmoa.\nCette vidéo m\u0026rsquo;a été tellement utile, surtout pour façonner mon intuition sur le produit vectoriel. L\u0026rsquo;identification entre les pseudo-vecteurs et les vecteurs est très logique, et pour moi, ça illustre vraiment pourquoi, dans les éléments finis, le champ magnétique a besoin d\u0026rsquo;éléments face (ou Raviart-Thomas) qui sont essentiellement des bivecteurs, comme le champ magnétique !\nOn peut également (grossièrement) interpréter le déterminant comme le volume d\u0026rsquo;une image, avec \\( f(e_1 \\wedge \u0026hellip; \\wedge e_n) = f(e_1) \\wedge \u0026hellip; \\wedge f(e_n) \\) et \\( {\\rm det}(f) = \\frac{f(e_1 \\wedge \u0026hellip; \\wedge e_n)}{e_1 \\wedge \u0026hellip; \\wedge e_n} \\), ce qui est tout juste beau.\n","date":"11 mars 2024","permalink":"https://tremelow.github.io/fr/blog/video-recommendations/2024-03-11-geometric-algebra/","section":"Articles de blog","summary":"","title":"sudgylacmoe -  A Swift Introduction to Geometric Algebra "},{"content":"This website is generated from Markdown using Hugo and the Congo theme! Here\u0026rsquo;s how I set it up.1\nWhy Hugo? # converts from Markdown, my note-taking \u0026ldquo;language\u0026rdquo; of choice large database of themes and examples fairly intuitive, template based recommended by a friend :) Also, everyone says Hugo is fast. As it is the only static site generator2 I\u0026rsquo;ve ever used, I can\u0026rsquo;t comment on this, but my site has never taken more than a couple of seconds to build. This is great when iterating on designs.\nHow Hugo? #Choosing a theme #I ended up choosing Congo for my theme, for a few reasons.\nmulti-page full of features but still fairly minimalist seemingly well documented through the example site, with accessible code customisable using (some) Tailwind CSS callout boxes! (though they still need some work) table of contents in blog posts Using a theme #Congo suggests 3 ways to import the theme. I chose the second, import it as a git submodule.\nupdates are easier than naive download (see tutorial in example site) easy access to the example site (go to the exampleSite folder and execute hugo server --themesDir ../..) no risk of having Hugo delete the cache and having to redownload the theme [!warning] This means that after cloning this repo, you should run use git clone --recursive, or follow the standard cloning with git submodule update --init themes/congo before building the website!\nMy previous website used Academic by WowChemy / HugoBlox, but it was too closed off for me. I like the original approach of Hugo with snippets and modularity, while with HugoBlox, anything outside of the box was inaccessible. With Congo, I was able to tweak and modify a lot of things on my own.\nThe project structure #I have a private git repo with the source,3 which I work on using hugo server. Once a blog post or modification is finished, I just run hugo which generates the website files in a public folder. This folder is linked to another git repo, which is synced to the website with Github Pages.4 I just have to do\ngit add . git commit -m \u0026#34;\u0026lt;date of update\u0026gt;\u0026#34; git push and we\u0026rsquo;re all set! The website gets updated almost immediately.\nMaybe importing the website as a submodule would also work, and it would make it appear in the online repo nicely, but this way works fine for me.\nMy customisation of Congo # Standard customisation leaves for publications and \u0026ldquo;about\u0026rdquo; page storing PDFs of publications in static/\u0026lt;leaf name\u0026gt; (in my case, \u0026lt;leaf name\u0026gt; is work) Enabled the light/dark button and header.layout = hybrid (see the Congo docs) Allowed custom alt text for the profile picture to give proper credit to Marie Morin Imported some icons from FontAwesome (fixed for dark mode, \u0026lt;path d=...\u0026gt; should be \u0026lt;path fill=\u0026quot;currentColor\u0026quot; d=...\u0026gt;) Imported a TikZJax script by benrbray Modified badge to allow href in it (because button was too clunky) Preview on footnote hover (thanks to 1 2), which still needs work Added a parameter reverseChronological to avoid chronological order All these modifications are visible either in assets or layouts.\nTo-do #There are many things I\u0026rsquo;m still not satisfied with at the moment, which I\u0026rsquo;ll hopefully tackle eventually.\nBlog homepage Flatten subsections to present every post on the list page (users can click on breadcrumbs to get back to a topic summary) Display parent topic if the post is part of a series Callout boxes Fix weird offset when it contains a list Make them foldable and give them a potential title (maybe using \u0026lt;details\u0026gt;) Footnotes preview/tooltip even on mobile fix position when the footnote is at the edge of the content fit width to content of footnote hover \u0026ldquo;Cite\u0026rdquo; button for publications, to make the Bibtex appear Dark / Light colour theme Post-process TikZ images to fit with the theme (graft the post-process of Obsidian TikZ with the most recent or most visible fork, as motivated by this StackOverflow answer) Different images depending on theme (reading list: 1 2 3) My own colour theme Colour to indicate current section in navigation bar (maybe superfluous with breadcrumbs) and/or position in Table of contents Automatic conversion from Obsidian to Hugo syntax (maybe with Amethyst?) Enable comments (see the Hugo docs) Improve icons support using e.g. the Icons module This is not a tutorial, what I\u0026rsquo;ve written is very sparse, and gets into the very specific details I spent time on despite reading tutorials.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nI\u0026rsquo;ve also read good things about Zola here and Astro here. The former uses a similar syntax to Hugo, but I\u0026rsquo;ve not yet faced issues with the unfortunate \u0026ldquo;magic\u0026rdquo; of Hugo which Zola supposedly prevents. The latter targets devs familiar with JavaScript and/or other website generator, which I\u0026rsquo;m not. Personally, I\u0026rsquo;d rather steal from use the large database of themes and examples for Hugo than tinker for days myself.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nMy source is actually public here, since I wanted the changes I made to the theme to be freely available. In the future, I plan on following this StackOverflow guide to separate between my drafts and my public modifications.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nThe Gitlab of most labs and universities have this feature too, nowadays! The CNRS webpage hosting does as well.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"5 mars 2024","permalink":"https://tremelow.github.io/fr/blog/hugo-blog-setup/","section":"Articles de blog","summary":"","title":"[EN] Making my website using Hugo"},{"content":" Pour ma première recommandation de vidéo, le choix m’a semblé évident : je voulais mettre en lumière la participation de Daria Ivanova au concours SoME3. Le sujet est à la fois léger et amusant, les explications sont limpides, et surtout, la présentation est vraiment originale et captivante.\nBonus : la gravité à l’autre pôle #On sait que la gravité à un pôle vaut (g), et que le volume de la planète en question correspond à environ 92,6 % de celui d’une sphère ayant la même gravité. Mais du coup, que se passe-t-il à l’autre pôle ? Quelle y est la valeur de la gravité ?\nEn appliquant la loi des cosinus (\\cos(\\varphi\u0026rsquo;) = 1 + r(\\varphi)^2 - 2r(\\varphi)\\cos(\\varphi)), et en utilisant la relation définissant la forme de la planète, on obtient : \\[ 1 - r(\\varphi)\\cos(\\varphi) = \\bigl( 1 + r(\\varphi)^2 - 2r(\\varphi)\\cos(\\varphi) \\bigr)^{3/2} \\] Autrement dit, pour chaque angle \\(\\varphi\\), il faut trouver la plus petite racine positive de la fonction paramétrique (pour \\(\\varphi \\in (0, \\pi/2)\\)) : \\[ \\rho \\mapsto f(\\rho, \\varphi) := \\bigl(1 - \\rho\\cos(\\varphi) \\bigr)^2 - \\bigl( 1 + \\rho^2 - 2\\rho\\cos(\\varphi) \\bigr)^3 \\]\nFonction paramétrique pour des angles espacés uniformément dans (varphi in [0, pi/2]). Les angles plus petits sont plus foncés et les plus grands plus clairs. code Au début, j’ai été surpris de constater que, pour les petits angles, la racine était supérieure à 1. Mais en y regardant de plus près, ça correspond bien au dessin.D’ailleurs, \\(\\rho = 1\\) semble être une bonne valeur initiale pour commencer la recherche numérique de racines.\nPour calculer la force gravitationnelle, on reprend la formule donnée dans la vidéo : $$ F = \\int_{\\theta = 0}^{2\\pi} \\int_{\\varphi=0}^{\\pi/2} \\int_{\\rho=0}^{r(\\varphi)} \\underbrace{\\frac{Gm\\delta}{\\rho^2}}_{\\text{force}} \\underbrace{ \\cos(\\varphi)}_{\\substack{\\text{projection sur}\\\\ \\text{l’axe vertical}} } \\underbrace{ \\rho^2 \\sin(\\varphi) {\\rm d}\\rho {\\rm d}\\varphi {\\rm d}\\theta }_{\\text{volume infinitésimal}} $$ Ce qui se simplifie en : \\[ F = \\underbrace{2\\pi G m \\delta}_{\\frac{5}{2}mg} \\int _0^{\\pi/2} r(\\varphi)\\cos(\\varphi)\\sin(\\varphi) , {\\rm d}\\varphi . \\] Un calcul numérique (code ) donne : \\[ \\frac{F}{mg} \\approx \\frac{5}{2} \\cdot 0.3949 \\approx 98.7%. \\] Autrement dit, la gravité diffère d’à peine 1,3 % entre les deux pôles de cette planète. C’est une variation tout à fait négligeable !\nÇa pourrait faire un bon projet de licence en calcul scientifique. Rien que le calcul de cette valeur finale, sans utiliser de modules tout prêts, demande déjà pas mal de travail. On pourrait même imaginer des méthodes de quadrature non standards, prenant en compte la dérivée de l’intégrande. D’après le théorème des fonctions implicites : \\[ r\u0026rsquo;(\\varphi) = -\\frac{\\partial_\\varphi f\\bigl(r(\\varphi), \\varphi\\bigr)}{\\partial_\\rho f\\bigl(r(\\varphi),\\varphi\\bigr)} \\] Ces méthodes pourraient s’appuyer sur l’interpolation d’Hermite, ou encore sur des quadratures modifiées fondées sur la formule d’Euler–Maclaurin. On pourra aussi jeter un œil aux méthodes NC-m-2 (en français). ","date":"4 mars 2024","permalink":"https://tremelow.github.io/fr/blog/video-recommendations/2024-03-04-dewdrop-planet/","section":"Articles de blog","summary":"","title":"Daria Ivanova - Affording a planet with geometry"},{"content":" This post assumes you know the base idea behind backward error analysis. If you are not, you should first read my previous blog post.\nAs is often the case, a good preliminary simplification is the linear case. Let\u0026rsquo;s consider here a one-dimensional linear ODE, which is, for \\(\\lambda \\in \\mathbb{R}\\) or in \\(\\mathbb{C}\\), $$ \\dot{u} =\\lambda u. $$ In this case, the flow is the linear map \\((t, u_0) \\mapsto \\varphi_t(u_0) = e^{t\\lambda}u_0\\), which also extends to higher dimensions when \\(\\lambda\\) is a matrix.1\nExplicit Euler #The explicit Euler scheme can be summarily written $$ \\Phi_h = \\operatorname{id} + h\\lambda . $$ For this simple case, the modified vector field \\(\\widetilde{\\lambda}_h\\) and the corrected vector field \\(\\mu_h\\) are found easily.\nModified equations #For modified equations, we look for \\(\\widetilde{\\lambda}_h\\) such that $$ \\widetilde{\\varphi}_h = \\Phi_h, \\qquad\\text{i.e.}\\qquad\\exp\\bigl( h\\widetilde{\\lambda}_h \\bigr) = \\operatorname{id} + h\\lambda . $$ Extending the logarithm to complex numbers,2 we find $$ \\widetilde{\\lambda}_h = \\frac{1}{h} \\log(1 + h\\lambda) . $$ Therefore, the modified equation is $$ \\frac{\\mathrm{d}}{\\mathrm{d}t} \\widetilde{u}_h = \\frac{1}{h}\\log(1 + h\\lambda), \\widetilde{u}_h . $$ Note that \\(\\widetilde{\\lambda}_h = \\lambda + \\mathcal{O}(h)\\), which corresponds to the first order of convergence of the scheme: in finite time \\(\\widetilde{u}_h(t) = u(t) + \\mathcal{O}(h)\\).\nLink with stability\nIn the real case, if \\(h\\lambda \u0026lt; -1\\) then \\(\\widetilde{\\lambda}_h\\) is complex, we write \\(h\\widetilde{\\lambda}_h = \\log|1 + h\\lambda| + i\\pi\\). If additionally \\(h\\lambda \u0026lt; -2\\), then \\(\\Re(\\widetilde{\\lambda}_h) \u0026gt; 0\\), so the method is unstable. Of course in the case \\(h\\lambda \u0026gt; 0\\), the method is also \u0026ldquo;unstable\u0026rdquo; in the standard sense, but not more than the original problem. In fact it is more stable in some sense, \\(\\widetilde{\\lambda}_h \u0026lt; \\lambda\\). Corrected equations / Modifying integrators #This time, we want the numerical solution of a corrected problem $$ \\dot v_h = \\mu_h \\dot{v}_h $$ to coincide with the exact solution of \\(\\dot u = \\lambda u\\). In other words, we want $$ 1 + h\\mu_h = e^{h\\lambda}, \\quad\\text{i.e.}\\quad \\mu_h = \\frac{1}{h} (e^{h\\lambda} - 1). $$ Then applying the Euler method with time-step \\(h\\) to the problem in \\(v_h\\) produces the exact solution, \\(v_n = u(nh)\\).\nNote that once the time-step is chosen for the corrected equation, it should not be changed! Look at the error of the method when correcting for \\(h = 0.1\\) and then simulating with a time-step \\(\\tau = 0.01\\). Common belief would be that reducing the time-step increases accuracy. It does, but it increases accuracy for a different problem.\nError as a function of time-step (tau) at time (T = 1) with (lambda = 1) code Application to the harmonic oscillator #Here is a comparison of these two concepts applied to a harmonic oscillator, $$ \\dot{u} = \\Lambda u, \\qquad \\Lambda = J := \\begin{pmatrix} 0 \u0026amp; -1 \\ 1 \u0026amp; 0 \\end{pmatrix} . $$\nFigure for the harmonic oscillator with both the modified and corrected equations, \\(h = 0.1\\) (CODE) # Error as a function of time-step (tau) at time (T = 1) with (lambda = 1) code Application to other schemes #This result may be extended to any standard Runge-Kutta method in a fairly straightforward manner using the stability function. For a method of Butcher tableau \\(\\begin{array}{c|c} c \u0026amp; A \\\\ \\hline \u0026amp; b^{\\sf T} \\end{array}\\) the stability function is given by the formula3 $$ r(z) = 1 + z b^{\\sf T} (\\mathrm{id} - zA)^{-1} \\mathbb{1} $$ where \\(\\mathbb{1} = (1, \\dots,1)^{\\sf T}\\).\nModified and corrected equations #For a Runge-Kutta method of stability function \\(z \\mapsto r(z)\\), the numerical scheme is exactly $$ \\Phi_h = r(h\\lambda) , $$ and \\(\\widetilde{\\lambda}_h\\) is such that for all \\(n \\in \\mathbb{N}\\), \\(e^{nh\\,\\widetilde{\\lambda}_h} = (\\Phi_h)^n = r(h\\lambda)^n\\). Evidently, $$ \\widetilde{\\lambda}_h = \\frac{1}{h} \\log\\bigl( r(h\\lambda) \\bigr), \\quad\\text{i.e.}\\quad \\frac{\\mathrm{d}}{\\mathrm{d}t} \\widetilde{u}_{n}(t) = \\frac{1}{h} \\log\\bigl( r(h\\lambda) \\bigr) \\widetilde{u}_{n}(t) . $$ As for corrected equations, \\(\\mu_h\\) may be obtained through the implicit relation $$ \\frac{1}{h} \\ln(r(h\\mu_h)) = \\lambda \\quad\\text{i.e.}\\quad r(h\\mu_h) = e^{h\\lambda} $$ Here are two specific methods,\nImplicit Euler: \\(\\widetilde{\\lambda}_h = -\\frac{1}{h}\\ln(1 - h\\lambda)\\), \\(\\mu_h = \\frac{1}{h}(1 - e^{-h\\lambda})\\). Midpoint or Crank-Nicolson: \\(\\widetilde{\\lambda}_h = \\frac{1}{h}\\ln\\left(\\frac{1 + \\frac{h}{2} \\lambda}{1-\\frac{h}{2}\\lambda} \\right)\\), \\(\\mu_h = \\frac{2}{h} \\frac{e^{h\\lambda} - 1}{e^{h\\lambda} + 1}\\) If the ODE on \\(\\widetilde{u}_n\\) is well-posed, the following statements are equivalent:\nThe method is of order \\(q\\) for linear problems; The modified vector field matches the initial one up to order \\(q\\), i.e. \\(\\frac{1}{h} \\ln\\bigl(r(h\\lambda)\\bigr) = \\lambda + \\mathcal{O}(h^q)\\); The \\(q\\)-th first derivatives of \\(\\widetilde{u}_h\\) at \\(t = 0\\) match those of the original equation. Investigate\nCheck that these three properties are indeed satisfied for the above examples. For a two-stage explicit method of order 2, find the order condition \\(b_1 + b_2 = 1\\) and \\(b_2 a_{12} = 1/2\\). Try to prove this proposition! Proof of the second property For the second property, a direct calculation yields $$ r(z) = 1 + z\\begin{pmatrix} b_{1} \u0026 b_{2} \\end{pmatrix} \\begin{pmatrix} 1 \u0026 0 \\\\ z a_{12} \u0026 1 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} = 1 + z(b_1 + b_2) + z^2 b_2 a_{12}, $$ from which we obtain the truncated series expansion $$ \\frac{1}{h}\\ln\\bigl(r(h\\lambda)\\bigr) = \\lambda(b_{1}+b_{2}) + h\\lambda b_{2}a_{12} - \\frac{h\\lambda}{2}(b_{1}+b_{2}) + \\mathcal{O}(h^2). $$ For the method to be of order 2, we need for all \\(\\lambda\\) $$ \\begin{cases} \\lambda(b_1 + b_2) = \\lambda, \\\\ \\lambda b_2 a_{12} - \\frac{\\lambda}{2}(b_1 + b_2) = 0, \\end{cases} $$ i.e. \\(b_1 + b_2 = 1\\) and \\(b_2 a_{12} = 1/2\\). The harmonic oscillator #In case of real data, i.e. \\(u \\in \\mathbb{R}^2\\), the previous multi-dimensional example involving \\(J = \\begin{pmatrix} 0 \u0026amp; -1 \\ 0 \u0026amp; 1 \\end{pmatrix}\\) may be identified with the complex problem \\(\\dot z = iz\\) with \\(z = u_1 + {\\rm i} u_2\\). Applying the previous identities with \\(\\lambda = {\\rm i}\\), we find\nExplicit Euler: \\(\\widetilde{\\lambda}_h = \\frac{1}{2h} \\log(1 + h^2) + \\frac{\\rm i}{h}\\arctan(h)\\) Implicit Euler: \\(\\widetilde{\\lambda}_h = \\frac{-1}{2h} \\log(1 + h^2) + \\frac{\\rm i}{h}\\arctan(h)\\), Midpoint: \\(\\widetilde{\\lambda}_h = \\frac{2{\\rm i}}{h} \\arctan(h/2)\\). For explicit Euler, \\(\\Re(\\widetilde{\\lambda}_h) \u0026gt; 0\\), therefore the method gains energy, meaning in this case that the module increases over time. For implicit Euler, \\(\\Re(\\widetilde{\\lambda}_h) \u0026lt; 0\\) so the method dissipates energy. For the midpoint method \\(\\Re(\\widetilde{\\lambda}_h) = 0\\), which indicates that energy is preserved.4 The method is said to be symplectic.\nWe can also find the corrected coefficients, respectively \\(\\mu_h = \\frac{1}{h}(e^{{\\rm i}h}-1)\\), \\(\\mu_h = \\frac{1}{h}(1 - e^{-{\\rm i}h})\\) and \\(\\mu_h = \\frac{2{\\rm i}}{h} \\tan(h/2)\\). Again, only the midpoint method generates an imaginary coefficient.\nThe multi-dimensional case #If \\(Z := h\\Lambda\\) is an operator of a \\(d\\)-dimensional space, a correct way to write the stability function would be $$ r(Z) = I_d + (I_d \\otimes b^{\\sf T}) \\left( I_d \\otimes I_s - Z \\otimes A \\right)^{-1} (Z \\otimes \\mathbb{1}_s) $$ where \\(\\otimes\\) is the Kronecker product, a useful tensor product for matrices.\nWhy the tensor product?\nGiven a Butcher tableau, the associated Runge-Kutta method is $$ \\begin{cases} k_1 = h \\Lambda \\left( u_n + a_{11} k_1 + \\dots + a_{1s} k_s \\right) \\\\ \\quad\\vdots \\\\ k_s = h \\Lambda \\left( u_n + a_{s1} k_1 + \\dots + a_{ss} k_s \\right) \\end{cases} $$ along with \\(u_{n+1} = u_n + b_1 k_1 + \u0026hellip; + b_s k_s\\). The vectors \\(k_i \\in \\mathbb{R}^d\\) may be collected in a tensor \\(\\mathbf{k} \\in \\mathbb{R}^d \\otimes \\mathbb{R}^s\\), and the fixed-point may then be written \\((I_d \\otimes I_s - h\\Lambda \\otimes A){\\bf k} = (h\\Lambda u_n) \\otimes \\mathbb{1}_s\\). The second part contracts the \\(\\mathbb{R}^s\\) part with \\(u_{n+1} = u_n + (I_d \\otimes b^{\\sf T}) {\\bf k}\\), where \\((I_d \\otimes b^{\\sf T}){\\bf k}\\) is identified from \\(\\mathbb{R}^d \\otimes \\mathbb{R}\\) to \\(\\mathbb{R}^d\\). This is cumbersome, so you\u0026rsquo;ll hopefully understand why I suck with the simple 1d notations. Just in case, here are the expressions for some common methods. $$ \\begin{aligned} \u0026amp;\\text{Exp. midpoint} \u0026amp;\u0026amp; r(Z) = \\operatorname{id} + Z \\left( \\operatorname{id} + {\\textstyle\\frac{1}{2}}Z \\right) . \\\\ \\\\ \u0026amp;\\text{Imp. midpoint} \u0026amp;\u0026amp; r(Z) = \\left( \\operatorname{id} - {\\textstyle\\frac{1}{2}} Z \\right)^{-1} (\\operatorname{id} + {\\textstyle\\frac{1}{2}} Z) \\\\ \\\\ \u0026amp; \\text{RK4} \u0026amp;\u0026amp; r(Z) = \\operatorname{id} + {\\textstyle\\frac{1}{6}}(K_1 + 2K_2 + 2K_3 + K_4 ) \\\\ \u0026amp;\u0026amp;\u0026amp; K_1 = Z,\\ K_2 = Z \\left( \\operatorname{id} + {\\textstyle\\frac{1}{2}} K_1 \\right),\\ \\\\ \u0026amp;\u0026amp;\u0026amp; K_3 = Z \\left( \\operatorname{id} + {\\textstyle\\frac{1}{2}} K_2 \\right), K_4 = Z \\left( \\operatorname{id} + K_3 \\right) \\end{aligned} $$\nReality check #The non-linear case #For a non-linear vector field, we must replace the exponential by the flow (morally, \\(\\varphi_h = e^{hf}\\)), and there are now additional terms in the power series, $$ \\begin{aligned} \\varphi_h \u0026amp;= \\operatorname{id} + hf + \\frac{h^2}{2}f\u0026rsquo;f + \\frac{h^3}{6}\\bigl[ f\u0026rsquo;\u0026rsquo;(f,f) + f\u0026rsquo;f\u0026rsquo;f \\bigr] \\\\ \u0026amp;+ \\frac{h^4}{4!} \\left[ f^{(3)}(f, f, f) + 3f\u0026rsquo;\u0026rsquo;(f, f\u0026rsquo;f) + f\u0026rsquo;f\u0026rsquo;\u0026rsquo;(f,f) + f\u0026rsquo;f\u0026rsquo;f\u0026rsquo;f \\right] + \\mathcal{O}(h^5) . \\end{aligned} $$ The computations become much more complex, and in general these series are purely formal, meaning that they diverge even for very small \\(h\\). Therefore the modified vector field \\(\\widetilde{f}_h\\) and the corrected vector field \\(g_h\\) can only be computed up to some power of \\(h\\), and the methods may be inaccurate for large time-steps.\nWe\u0026rsquo;re not supposed to know the flow #Of course these are only examples to explain the reasoning of the method and why it has a chance to work. In practice, we do not know \\(e^{h\\lambda}\\) (or its equivalent, the flow \\(\\varphi_h\\) or \\(e^{h\\Lambda}\\)), because if we did there would be no need for numerical methods. In the linear case, there is actually a lot of literature (which I\u0026rsquo;m not familiar with) on computing accurate high-order approximation of matrix exponentials. I don\u0026rsquo;t know if symplecticity is important for these applications.\nI won\u0026rsquo;t discuss infinite dimension, i.e. PDEs, because everything is always more complicated for PDEs.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nIn the multi-dimensional case \\(\\dot u = \\Lambda u\\), we may use the notation \\(\\ln(\\mathrm{id} + h\\Lambda) = \\sum\\limits_{n \\geq 1} \\frac{(-1)^{n+1}}{n}(h \\Lambda)^n\\), valid for \\(h |\\Lambda| \u0026lt; 1\\). For other cases, see for instance the Wikipedia page.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nSee e.g. E. Hairer, G. Wanner, Solving ordinary differential equations II. Stiff and Differential-Algebraic Problems (1996) \u0026ndash; Sec. IV.3\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nIn the generic non-linear case, the energy would be preserved up to a \\(\\mathcal{O}(h^2)\\) term.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"1 mars 2024","permalink":"https://tremelow.github.io/fr/blog/backward-error-analysis/02-linear-bea/","section":"Articles de blog","summary":"","title":"[EN] Linear backward error analysis"},{"content":" There are two main areas in backward error analysis (b.e.a.), which are modified equations and modifying integrators. The first serve to study the properties of integrators, while the second improves the convergence of such integrators. Let\u0026rsquo;s have a look!\nModified equations #As mentioned previously, backward error analysis serves to find a so-called \u0026ldquo;modified\u0026rdquo; vector field for which the exact solution matches the numerical solution at discrete times. This is tentatively illustrated in the following diagram\nwhere \\(\\varphi_h\\) represents the exact integration of the ODE and \\(\\Phi_h\\) represents the application of a numerical method. The vector field \\(u \\mapsto f(u)\\) is the original vector field on which the numerical method is applied and \\(u \\mapsto \\widetilde{f}_h(u)\\) is the aforementioned modified vector field.\nAs an illustration1 here is a Lotka-Volterra problem \\[\\begin{cases}\\dot u_1 = u_1(2 - u_2), \\quad \u0026amp; u_1(0) = 2, \\\\ \\dot u_2 = u_2(u_1 - 1), \u0026amp; u_2(0) = 2 . \\end{cases} \\] simulated using the explicit Euler method, overlaid with the exact solutions of both the original problem and the modified problem, in phase-space.\nExact and numerical trajectories (with the Euler method) for the Lotka-Volterra problem \\(\\dot u = u(2-v),\\ \\dot v = v(u-1)\\) with initial condition \\(u(0) = v(0) = 2\\). Here the dashed lines are the exact solutions of (for now unspecified) modified differential equations. Notice that for each method, the line exactly2 matches the markers which denote the numerical solution.\nModifying integrators / Corrected equations #More recently, it has also been used to \u0026ldquo;correct\u0026rdquo; the vector field in simulations and improve numerical convergence. Once again, let me try to illustrate this with a diagram:\nUsing the notations of the first diagram, we want to find \\(g_h\\) such that \\(\\widetilde{g}_h = f\\), i.e. we want to somehow \u0026ldquo;invert\u0026rdquo; the backward error analysis. Unsurprisingly, this corrected field \\(g_h\\) depends on the time-step \\(h\\).\nConsidering again the Lotka-Volterra problem \\(\\dot u_1 = u_1(2-u_2)\\), \\(\\dot u_2 = u_2(u_1-1)\\), \\(u_1(0)= u_2(0) = 2\\) and the explicit Euler method, let\u0026rsquo;s look at the numerical solution of the corrected vector field and compare it with the exact solutions of both the original problem and the corrected problem.\nExact and numerical trajectories (with the Euler method) for the Lotka-Volterra problem \\(\\dot u = u(2-v),\\ \\dot v = v(u-1)\\) with initial condition \\(u(0) = v(0) = 2\\). This time, the numerical solution perfectly matches the exact solution at the discrete times! The error of the scheme is compensated by choosing the right corrected vector field.\nWhy should you care? #While there are many uses for both methods, here are two common use cases for each approach.\nModified equations\nfind the order of convergence of a numerical scheme study the long-time properties of integrators (such as energy preservation) Corrected equations:\nimprove the order of convergence of integrators (obviously) appears in machine learning of differential equations If this is all too abstract, you may read the next post with examples in the case of linear differential equations.\nThese illustrations are possible thanks to the Julia package B-Series. Thanks to the devs!\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nIn reality, the curves do not exactly match: the modified vector field \\(\\widetilde{f}_h\\) is computed as a truncated power series in \\(h\\), which induces a small error.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"28 février 2024","permalink":"https://tremelow.github.io/fr/blog/backward-error-analysis/01-motivating-bea/","section":"Articles de blog","summary":"","title":"[EN] Motivating backward error analysis"},{"content":" I want to discuss an interpretation of discrete approximations \\(u_n \\approx u(nh)\\) obtained from numerical schemes with time-step \\(h\\) as the continuous (exact) solution \\(t \\mapsto \\widetilde{u}_h(t)\\) of modified differential equations. This interpretation, called backward error analysis (BEA) is useful for long-time properties of numerical integrators, or even just their order of accuracy. Additionally, this relationship can be somehow \u0026ldquo;reversed\u0026rdquo; to improve numerical accuracy, which I\u0026rsquo;ll illustrate in this post.\nMy goal here is to present some ideas and to illustrate the results with some simple test cases, to share my initial wonder for BEA. I find that most of the literature quickly gets into the technical details of the how and why this works. There are elegant algebraic structures hidden here, with lots of applications and extensions and great maths\u0026mdash;all of which deserve this technicality! But it can also be a stumbling block for the understanding of the idea behind BEA. Readers who want to go further can peruse the following works:\nLecture notes of Ernst Hairer PDF Chartier, Hairer, Vilmart, \u0026ldquo;Numerical integrators based on modified differential equations\u0026rdquo; in Math. of Comp. (2007) DOI Chartier, Hairer, Vilmart, \u0026ldquo;Algebraic Structures of B-series\u0026rdquo; in FoCM (2010) DOI Hairer, Lubich, Wanner, Geometric Numerical Integration (2006) DOI ","date":null,"permalink":"https://tremelow.github.io/fr/blog/backward-error-analysis/","section":"Articles de blog","summary":"","title":"[EN] A gentle introduction to backward error analysis"},{"content":"","date":null,"permalink":"https://tremelow.github.io/fr/categories/","section":"Categories","summary":"","title":"Categories"},{"content":"","date":null,"permalink":"https://tremelow.github.io/fr/categories/enseignement/","section":"Categories","summary":"","title":"Enseignement"},{"content":"","date":null,"permalink":"https://tremelow.github.io/fr/tags/licence/","section":"Tags","summary":"","title":"Licence"},{"content":"","date":null,"permalink":"https://tremelow.github.io/fr/tags/ludique/","section":"Tags","summary":"","title":"Ludique"},{"content":"","date":null,"permalink":"https://tremelow.github.io/fr/tags/","section":"Tags","summary":"","title":"Tags"},{"content":" Ce sujet PDF est inspiré d’une superbe vidéo de Jacob Yatsko dans laquelle les nombres de Fibonacci modulo \\(p \\in \\mathbb{N}^*\\) sont placés sur un cercle. À partir d’un certain rang (qui dépend de \\(p\\)), la suite est périodique; ce rang est appelé période de Pisano. L’objectif du TP est de reproduire cette visualisation sur le cercle avec Scilab.\nÉtant donné que le sujet s’adresse aux élèves en fin de première année de formation GEII à l’IUT, la notion de modulo n’est pas supposée connue, donc elle est présentée rapidement. En accord avec l’esprit du cours Outils Logiciels, les questions mélangent raisonnements mathématiques et programmation. Notamment, on se sert de la programmation pour calculer la période de Pisano. Ce sujet permet en outre d’introduire de la notion d’erreur d’arrondis. En effet, comme les termes de la suite de Fibonacci croissent de manière exponentielle, on ne peut pas se contenter de les calculer puis de les prendre modulo \\(p\\). Il faut faire tous les calculs modulo \\(p\\).\nLes questions primordiales sont indiquées avec un cœur et les questions standard avec un triangle. Les élèves qui souhaitent approfondir le sujet et leurs connaissances mathématiques (ou simplement améliorer leur note) peuvent répondre aux questions indiquées par un symbole de pique. De cette manière, les connaissances attendues par l’étudiant sont rendues explicites.\nIl est à noter que ce sujet a été pensé comme un mini-projet en temps libre sur plusieurs semaines, et donc certaines questions sont difficiles. Les élèves sont encouragé-e-s à soliciter les enseignant-e-s pour se débloquer.\n","date":"11 mai 2022","permalink":"https://tremelow.github.io/fr/blog/tp-pisano/","section":"Articles de blog","summary":"","title":"TP: Visualisation de la période de Pisano"},{"content":"Je suis maître de conférences à Lens, à l\u0026rsquo;IUT (département d\u0026rsquo;informatique) et au Laboratoire de Mathématiques de Lens.\nPrécédemment, j\u0026rsquo;étais post-doctorant dans l\u0026rsquo;équipe Macaron (anciennement TONUS) et IRMA de l\u0026rsquo;Inria à Strasbourg, où je travaillais avec C. Courtès, E. Franck, M. Kraus et L. Navoret. Avant cela, j\u0026rsquo;étais assistant diplômé à l\u0026rsquo;Ensimag en tant que membre du Laboratoire Jean Kuntzmann à Grenoble. J\u0026rsquo;ai obtenu mon doctorat en décembre 2021 à Rennes sous la direction de P. Chartier et M. Lemou, au sein de l\u0026rsquo;équipe Inria MINGuS.\nMes recherches portent sur les méthodes multi-échelles et géométriques dans un contexte numérique. Plus précisément, j\u0026rsquo;étudie les propriétés des développements asymptotiques et les utilise pour obtenir une meilleure convergence numérique. On peut citer comme exemples les problèmes de relaxation rigide tels que l\u0026rsquo;équation linéaire de Boltzmann, l\u0026rsquo;équation de Bloch hautement oscillatoire ou le comportement à long terme de la dynamique des centres directeurs. Dans le cadre de mon post-doctorat, j\u0026rsquo;ai travaillé sur l\u0026rsquo;apprentissage automatique géométrique, à savoir le lien entre le schéma numérique utilisé lors de l\u0026rsquo;inférence et les propriétés des champs vectoriels appris par l\u0026rsquo;apprentissage automatique géométrique lors de la reconstruction des champs vectoriels.\n","date":null,"permalink":"https://tremelow.github.io/fr/about/","section":"Site personnel de Léopold Trémant","summary":"","title":"À propos"},{"content":" Journals Clémentine Courtès, Emmanuel Franck, Michael Kraus, Laurent Navoret, LT, \u0026ldquo;Neural non-canonical Hamiltonian dynamics for long-time simulations\u0026rdquo; (2025). Preprint. PDF HAL code Brigitte Bidégaray-Fesquet, Clément Jourdana, LT, \u0026ldquo;Multi-frequency averaging and uniform accuracy towards numerical approximations for a Bloch model\u0026rdquo; (2023). In Communications in Mathematical Sciences. PDF HAL Philippe Chartier, Mohammed Lemou, Florian Méhats, LT, \u0026ldquo;Averaging in a Nutshell\u0026rdquo; (2024). To be submitted. PDF Philippe Chartier, Mohammed Lemou, LT, \u0026ldquo;A uniformly accurate numerical method for a class of dissipative systems\u0026rdquo; (2021). In Mathematics of Computation. PDF DOI Recent talks NODYCON 2025, \u0026ldquo;Learning non-canonical Hamiltonian dynamics\u0026rdquo; slides Numkin 2024, \u0026ldquo;Learning non-canonical Hamiltonian dynamics for the guiding center problem\u0026rdquo; slides Thesis LT, \u0026ldquo;Méthodes d’analyse asymptotique et d’approximation numérique\u0026rdquo; (2021). PhD thesis. PDF slides ","date":null,"permalink":"https://tremelow.github.io/fr/work/","section":"Site personnel de Léopold Trémant","summary":"","title":"Publications"}]