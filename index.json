[{"content":" My tribulations about maths and maybe other things. ","date":null,"permalink":"/blog/","section":"Blog posts","summary":"","title":"Blog posts"},{"content":"Le cours R5.A.12 - Modélisation mathématique de 2024-2025 de l\u0026rsquo;IUT d\u0026rsquo;Informatique de Lens s\u0026rsquo;intéresse à l\u0026rsquo;apprentissage. L\u0026rsquo;objectif est d\u0026rsquo;introduire les outils mathématiques nécessaires à la bonne compréhension des bases de ces méthodes, à travers trois composantes :\nReprésentation : Un modèle qui peut être implémenté (l\u0026rsquo;architecture, le nombre de paramètres\u0026hellip;) ; Évaluation : Une loss, une fonction objectif ou de score ; Optimisation : Une manière efficace d\u0026rsquo;ajuster les paramètres. On ne considère que l\u0026rsquo;apprentissage supervisé, ce qui permet de se concentrer sur les parties 1 et 3. On commence par une représentation simple d\u0026rsquo;approximation affine et régression linéaire pour se concentrer sur l\u0026rsquo;optimisation. Une fois le pipeline d\u0026rsquo;optimisation en PyTorch est assimilé sur cet exemple, on introduit les perceptrons multi-couches, puis les transformeurs.\nLes aspects théoriques sont illustrés par des TPs, disponibles dans la liste suivante, fréquemment mise à jour :\nTP1.1 - Régression linéaire ipynb TP1.2 - Descente de gradient ipynb TP1.3 - Optimisation en PyTorch ipynb TP1.4 - Apprentissage par lots ipynb py Les vidéos inaccessibles sur le réseau de l\u0026rsquo;IUT :\nDeepmath - Tenseurs ","date":"11 June 2024","permalink":"/blog/introduction_deep_learning/","section":"Blog posts","summary":"","title":"Introduction au deep learning"},{"content":" tremant-research \u0026lt;at\u0026gt; pm.me\nDrawing by Marie Morin\nMy CV (in French)\nWelcome!\nI\u0026rsquo;m a young researcher in numerical analysis. Here you might read about long-time integration, asymptotic expansions and machine learning.\n","date":null,"permalink":"/","section":"Website of Léopold Trémant","summary":"","title":"Website of Léopold Trémant"},{"content":" A video popped up in my feed this week. It discusses a game which really piqued my attention. See, I actually submitted a very similar game to young students for MATh.en.JEANS this year.\nThe MATh.en.JEANS game #The game was the following:\nÉmilie and Manon play \u0026ldquo;heads or tails\u0026rdquo; (H or T) but instead of betting on H or T, they each bet on a pattern. Émilie bets on HTH and Manon bets on HTT. Every time one of their a pattern appears (with overlap), the player who chose it gets a point. The game ends when a player reaches 3 points.\nFor instance, denoting Émilie\u0026rsquo;s pattern in italics and Manon\u0026rsquo;s pattern in bold, here\u0026rsquo;s a random game:\nHTHTTHTTTHHHTT\nHere the game stops because Manon wins. After simulating a million games, though, it seems that Émilie wins far more often. How can we explain this?\nThe point is not for me to give solutions to this problem, so I haven\u0026rsquo;t thought about the problem too much, but the students found it fun and challenging. They weren\u0026rsquo;t able to crack it, even after a while. As for my part, poking holes in their conjectures (e.g. \u0026ldquo;Émilie can overlap, not Manon\u0026rdquo;) was interesting.\nThe HH-HT game #In the video, the initial idea is the same: each player chooses a pattern and counts them with overlap. Except the patterns are shorter and the number of rounds is fixed: the points are counted after 100 flips. Who wins more between HH and HT?\nMihai Nica takes his time to prove that HT wins more, by how much, and how the number of rounds may affect the result. While, the explanation is a bit technical for high-schoolers, the visualisations are great and I found it super engaging! His code is available in a Google Colab in the description, as well.\nAny ideas how this can serve as a stepping stone to compare HTT with HTH?\n","date":"15 May 2024","permalink":"/blog/video-recommendations/2024-05-17-hh-vs-ht/","section":"Blog posts","summary":"","title":"Mihai Nica - Alice HH vs Bob HT"},{"content":" If you\u0026rsquo;re online and interested in the intersection of maths, programming and video games, you\u0026rsquo;ve probably seen the Quake III \u0026ldquo;fast inverse square root\u0026rdquo; snippet.\nfloat q_rsqrt(float number) { long i; float x2, y; const float threehalfs = 1.5F; x2 = number * 0.5F; y = number; i = * ( long * ) \u0026amp;y; // evil floating point bit level hacking i = 0x5f3759df - ( i \u0026gt;\u0026gt; 1 ); // what the fuck? y = * ( float * ) \u0026amp;i; y = y * ( threehalfs - ( x2 * y * y ) ); // 1st iteration // y = y * ( threehalfs - ( x2 * y * y ) ); // 2nd iteration, this can be removed return y; } This made the rounds a while ago, because not only is it funny to see professional code with such incredibly descriptive comments, but also because every line of this short code is perfectly incomprehensible. In twenty minutes, this video by Nemean explains this snippet, from the implementation of floating point numbers to a very smart implementation of mathematical functions (which I won\u0026rsquo;t spoil).\n","date":"18 March 2024","permalink":"/blog/video-recommendations/2024-03-18-inverse-sqrt/","section":"Blog posts","summary":"","title":"Nemean - Fast Inverse Square Root — A Quake III Algorithm"},{"content":" This week, I\u0026rsquo;m suggesting this video by sudgylacmoa.\nThis has been so useful to me, it really helped shape my intuition about the cross product. The identification between pseudo-vectors and vectors makes so much sense, and for me it really illustrates why, in finite elements, the magnetic field needs face (or Raviart\u0026ndash;Thomas) elements which are basically bivectors\u0026mdash;just like the magnetic field!\nAlso, this can be used to interpret the determinant as (crudely) the volume of the image, with \\( f(e_1 \\wedge \u0026hellip; \\wedge e_n) = f(e_1) \\wedge \u0026hellip; \\wedge f(e_n) \\) and \\( {\\rm det}(f) = \\frac{f(e_1 \\wedge \u0026hellip; \\wedge e_n)}{e_1 \\wedge \u0026hellip; \\wedge e_n} \\), which is just lovely.\n","date":"11 March 2024","permalink":"/blog/video-recommendations/2024-03-11-geometric-algebra/","section":"Blog posts","summary":"","title":"sudgylacmoe -  A Swift Introduction to Geometric Algebra "},{"content":"This website is generated from Markdown using Hugo and the Congo theme! Here\u0026rsquo;s how I set it up.1\nWhy Hugo? # converts from Markdown, my note-taking \u0026ldquo;language\u0026rdquo; of choice large database of themes and examples fairly intuitive, template based recommended by a friend :) Also, everyone says Hugo is fast. As it is the only static site generator2 I\u0026rsquo;ve ever used, I can\u0026rsquo;t comment on this, but my site has never taken more than a couple of seconds to build. This is great when iterating on designs.\nHow Hugo? #Choosing a theme #I ended up choosing Congo for my theme, for a few reasons.\nmulti-page full of features but still fairly minimalist seemingly well documented through the example site, with accessible code customisable using (some) Tailwind CSS callout boxes! (though they still need some work) table of contents in blog posts Using a theme #Congo suggests 3 ways to import the theme. I chose the second, import it as a git submodule.\nupdates are easier than naive download (see tutorial in example site) easy access to the example site (go to the exampleSite folder and execute hugo server --themesDir ../..) no risk of having Hugo delete the cache and having to redownload the theme [!warning] This means that after cloning this repo, you should run use git clone --recursive, or follow the standard cloning with git submodule update --init themes/congo before building the website!\nMy previous website used Academic by WowChemy / HugoBlox, but it was too closed off for me. I like the original approach of Hugo with snippets and modularity, while with HugoBlox, anything outside of the box was inaccessible. With Congo, I was able to tweak and modify a lot of things on my own.\nThe project structure #I have a private git repo with the source,3 which I work on using hugo server. Once a blog post or modification is finished, I just run hugo which generates the website files in a public folder. This folder is linked to another git repo, which is synced to the website with Github Pages.4 I just have to do\ngit add . git commit -m \u0026#34;\u0026lt;date of update\u0026gt;\u0026#34; git push and we\u0026rsquo;re all set! The website gets updated almost immediately.\nMaybe importing the website as a submodule would also work, and it would make it appear in the online repo nicely, but this way works fine for me.\nMy customisation of Congo # Standard customisation leaves for publications and \u0026ldquo;about\u0026rdquo; page storing PDFs of publications in static/\u0026lt;leaf name\u0026gt; (in my case, \u0026lt;leaf name\u0026gt; is work) Enabled the light/dark button and header.layout = hybrid (see the Congo docs) Allowed custom alt text for the profile picture to give proper credit to Marie Morin Imported some icons from FontAwesome (fixed for dark mode, \u0026lt;path d=...\u0026gt; should be \u0026lt;path fill=\u0026quot;currentColor\u0026quot; d=...\u0026gt;) Imported a TikZJax script by benrbray Modified badge to allow href in it (because button was too clunky) Preview on footnote hover (thanks to 1 2), which still needs work Added a parameter reverseChronological to avoid chronological order All these modifications are visible either in assets or layouts.\nTo-do #There are many things I\u0026rsquo;m still not satisfied with at the moment, which I\u0026rsquo;ll hopefully tackle eventually.\nBlog homepage Flatten subsections to present every post on the list page (users can click on breadcrumbs to get back to a topic summary) Display parent topic if the post is part of a series Callout boxes Fix weird offset when it contains a list Make them foldable and give them a potential title (maybe using \u0026lt;details\u0026gt;) Footnotes preview/tooltip even on mobile fix position when the footnote is at the edge of the content fit width to content of footnote hover \u0026ldquo;Cite\u0026rdquo; button for publications, to make the Bibtex appear Dark / Light colour theme Post-process TikZ images to fit with the theme (graft the post-process of Obsidian TikZ with the most recent or most visible fork, as motivated by this StackOverflow answer) Different images depending on theme (reading list: 1 2 3) My own colour theme Colour to indicate current section in navigation bar (maybe superfluous with breadcrumbs) and/or position in Table of contents Automatic conversion from Obsidian to Hugo syntax (maybe with Amethyst?) Enable comments (see the Hugo docs) Improve icons support using e.g. the Icons module This is not a tutorial, what I\u0026rsquo;ve written is very sparse, and gets into the very specific details I spent time on despite reading tutorials.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nI\u0026rsquo;ve also read good things about Zola here and Astro here. The former uses a similar syntax to Hugo, but I\u0026rsquo;ve not yet faced issues with the unfortunate \u0026ldquo;magic\u0026rdquo; of Hugo which Zola supposedly prevents. The latter targets devs familiar with JavaScript and/or other website generator, which I\u0026rsquo;m not. Personally, I\u0026rsquo;d rather steal from use the large database of themes and examples for Hugo than tinker for days myself.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nMy source is actually public here, since I wanted the changes I made to the theme to be freely available. In the future, I plan on following this StackOverflow guide to separate between my drafts and my public modifications.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nThe Gitlab of most labs and universities have this feature too, nowadays! The CNRS webpage hosting does as well.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"5 March 2024","permalink":"/blog/hugo-blog-setup/","section":"Blog posts","summary":"","title":"Making my website using Hugo"},{"content":" For my first video recommendation, it seemed obvious to me to spotlight Daria Ivanova\u0026rsquo;s SoME3 submission. The topic is light-hearted, the explanations are clear, and of course the presentation style is so amazing and original.\nBonus: gravity at the other pole #Now, we know that the gravity at one pole is equal to \\(g\\), and that the volume is approximately 92.6% of a sphere with the same gravity. But what\u0026rsquo;s the gravity at the other pole?\nUsing the law of cosines, \\(\\cos(\\varphi\u0026rsquo;) = 1 + r(\\varphi)^2 -2r(\\varphi) \\cos(\\varphi)\\), and since by definition, \\(r(\\varphi)\\cos(\\varphi) + \\cos(\\varphi\u0026rsquo;)^{3/2} = 1\\), we find \\[ 1 - r(\\varphi)\\cos(\\varphi) = \\bigl( 1 + r(\\varphi)^2 - 2r(\\varphi)\\cos(\\varphi) \\bigr)^{3/2} \\] Therefore, at fixed angle \\(\\varphi\\), we\u0026rsquo;re looking for the smallest positive root of the parametric function, for \\(\\varphi \\in (0, \\pi/2)\\), \\[ \\rho \\mapsto f(\\rho, \\varphi) := \\bigl(1 - \\rho\\cos(\\varphi) \\bigr)^2 - \\bigl( 1 + \\rho^2 - 2\\rho\\cos(\\varphi) \\bigr)^3 \\]\nParametric function for equally spaced angles (varphi in [0, pi/2]). Smaller angles are darker and larger angles are lighter. code At first, I was surprised to see that for small angles, the root was greater than 1, but that actually holds up with the drawing. Also, it seems that \\(\\rho = 1\\) would be a good initial condition for root finding.\nTo compute the force, we use the formula from the video, $$ F = \\int_{\\theta = 0}^{2\\pi} \\int_{\\varphi=0}^{\\pi/2} \\int_{\\rho=0}^{r(\\varphi)} \\underbrace{\\frac{Gm\\delta}{\\rho^2}}_{\\text{force}} \\underbrace{ \\cos(\\varphi)}_{\\substack{\\text{project on}\\\\ \\text{vertical}\\\\ \\text{component}} } \\underbrace{ \\rho^2 \\sin(\\varphi) {\\rm d}\\rho {\\rm d}\\varphi {\\rm d}\\theta }_{ \\text{infinitesimal volume} } $$ This simplifies into \\[ F = \\underbrace{2\\pi G m \\delta}_{\\frac{5}{2}mg} \\int _0^{\\pi/2} r(\\varphi)\\cos(\\varphi)\\sin(\\varphi) , {\\rm d}\\varphi . \\] A numerical computation code yields \\[ \\frac{F}{mg} \\approx \\frac{5}{2} \\cdot 0.3949 \\approx 98.7%. \\] Therefore, if this is indeed the minimal spot, the gravity is off by at most 1.3% on this planet. That seems very manageable.\nThis could make a cool undergrad project in scientific computing. Just computing this final quantity without leveraging pre-defined modules is a bit of work. One could even consider non-standard quadrature rules involving the derivative of the integrand. Owing to the implicit function theorem: \\[ r\u0026rsquo;(\\varphi) = -\\frac{\\partial_\\varphi f\\bigl(r(\\varphi), \\varphi\\bigr)}{\\partial_\\rho f\\bigl(r(\\varphi),\\varphi\\bigr)} \\] Such methods could be based on Hermite interpolation, or be modified quadratures using the Euler\u0026ndash;Maclaurin formula. See also NC-m-2 methods (in French). ","date":"4 March 2024","permalink":"/blog/video-recommendations/2024-03-04-dewdrop-planet/","section":"Blog posts","summary":"","title":"Daria Ivanova - Affording a planet with geometry"},{"content":"Mathematics or education-related videos which I found great, hopefully updated weekly!\n","date":null,"permalink":"/blog/video-recommendations/","section":"Blog posts","summary":"","title":"Video recommendations"},{"content":" This post assumes you know the base idea behind backward error analysis. If you are not, you should first read my previous blog post.\nAs is often the case, a good preliminary simplification is the linear case. Let\u0026rsquo;s consider here a one-dimensional linear ODE, which is, for \\(\\lambda \\in \\mathbb{R}\\) or in \\(\\mathbb{C}\\), $$ \\dot{u} =\\lambda u. $$ In this case, the flow is the linear map \\((t, u_0) \\mapsto \\varphi_t(u_0) = e^{t\\lambda}u_0\\), which also extends to higher dimensions when \\(\\lambda\\) is a matrix.1\nExplicit Euler #The explicit Euler scheme can be summarily written $$ \\Phi_h = \\operatorname{id} + h\\lambda . $$ For this simple case, the modified vector field \\(\\widetilde{\\lambda}_h\\) and the corrected vector field \\(\\mu_h\\) are found easily.\nModified equations #For modified equations, we look for \\(\\widetilde{\\lambda}_h\\) such that $$ \\widetilde{\\varphi}_h = \\Phi_h, \\qquad\\text{i.e.}\\qquad\\exp\\bigl( h\\widetilde{\\lambda}_h \\bigr) = \\operatorname{id} + h\\lambda . $$ Extending the logarithm to complex numbers,2 we find $$ \\widetilde{\\lambda}_h = \\frac{1}{h} \\log(1 + h\\lambda) . $$ Therefore, the modified equation is $$ \\frac{\\mathrm{d}}{\\mathrm{d}t} \\widetilde{u}_h = \\frac{1}{h}\\log(1 + h\\lambda), \\widetilde{u}_h . $$ Note that \\(\\widetilde{\\lambda}_h = \\lambda + \\mathcal{O}(h)\\), which corresponds to the first order of convergence of the scheme: in finite time \\(\\widetilde{u}_h(t) = u(t) + \\mathcal{O}(h)\\).\nLink with stability\nIn the real case, if \\(h\\lambda \u0026lt; -1\\) then \\(\\widetilde{\\lambda}_h\\) is complex, we write \\(h\\widetilde{\\lambda}_h = \\log|1 + h\\lambda| + i\\pi\\). If additionally \\(h\\lambda \u0026lt; -2\\), then \\(\\Re(\\widetilde{\\lambda}_h) \u0026gt; 0\\), so the method is unstable. Of course in the case \\(h\\lambda \u0026gt; 0\\), the method is also \u0026ldquo;unstable\u0026rdquo; in the standard sense, but not more than the original problem. In fact it is more stable in some sense, \\(\\widetilde{\\lambda}_h \u0026lt; \\lambda\\). Corrected equations / Modifying integrators #This time, we want the numerical solution of a corrected problem $$ \\dot v_h = \\mu_h \\dot{v}_h $$ to coincide with the exact solution of \\(\\dot u = \\lambda u\\). In other words, we want $$ 1 + h\\mu_h = e^{h\\lambda}, \\quad\\text{i.e.}\\quad \\mu_h = \\frac{1}{h} (e^{h\\lambda} - 1). $$ Then applying the Euler method with time-step \\(h\\) to the problem in \\(v_h\\) produces the exact solution, \\(v_n = u(nh)\\).\nNote that once the time-step is chosen for the corrected equation, it should not be changed! Look at the error of the method when correcting for \\(h = 0.1\\) and then simulating with a time-step \\(\\tau = 0.01\\). Common belief would be that reducing the time-step increases accuracy. It does, but it increases accuracy for a different problem.\nError as a function of time-step (tau) at time (T = 1) with (lambda = 1) code Application to the harmonic oscillator #Here is a comparison of these two concepts applied to a harmonic oscillator, $$ \\dot{u} = \\Lambda u, \\qquad \\Lambda = J := \\begin{pmatrix} 0 \u0026amp; -1 \\ 1 \u0026amp; 0 \\end{pmatrix} . $$\nFigure for the harmonic oscillator with both the modified and corrected equations, \\(h = 0.1\\) (CODE) # Error as a function of time-step (tau) at time (T = 1) with (lambda = 1) code Application to other schemes #This result may be extended to any standard Runge-Kutta method in a fairly straightforward manner using the stability function. For a method of Butcher tableau \\(\\begin{array}{c|c} c \u0026amp; A \\\\ \\hline \u0026amp; b^{\\sf T} \\end{array}\\) the stability function is given by the formula3 $$ r(z) = 1 + z b^{\\sf T} (\\mathrm{id} - zA)^{-1} \\mathbb{1} $$ where \\(\\mathbb{1} = (1, \\dots,1)^{\\sf T}\\).\nModified and corrected equations #For a Runge-Kutta method of stability function \\(z \\mapsto r(z)\\), the numerical scheme is exactly $$ \\Phi_h = r(h\\lambda) , $$ and \\(\\widetilde{\\lambda}_h\\) is such that for all \\(n \\in \\mathbb{N}\\), \\(e^{nh\\,\\widetilde{\\lambda}_h} = (\\Phi_h)^n = r(h\\lambda)^n\\). Evidently, $$ \\widetilde{\\lambda}_h = \\frac{1}{h} \\log\\bigl( r(h\\lambda) \\bigr), \\quad\\text{i.e.}\\quad \\frac{\\mathrm{d}}{\\mathrm{d}t} \\widetilde{u}_{n}(t) = \\frac{1}{h} \\log\\bigl( r(h\\lambda) \\bigr) \\widetilde{u}_{n}(t) . $$ As for corrected equations, \\(\\mu_h\\) may be obtained through the implicit relation $$ \\frac{1}{h} \\ln(r(h\\mu_h)) = \\lambda \\quad\\text{i.e.}\\quad r(h\\mu_h) = e^{h\\lambda} $$ Here are two specific methods,\nImplicit Euler: \\(\\widetilde{\\lambda}_h = -\\frac{1}{h}\\ln(1 - h\\lambda)\\), \\(\\mu_h = \\frac{1}{h}(1 - e^{-h\\lambda})\\). Midpoint or Crank-Nicolson: \\(\\widetilde{\\lambda}_h = \\frac{1}{h}\\ln\\left(\\frac{1 + \\frac{h}{2} \\lambda}{1-\\frac{h}{2}\\lambda} \\right)\\), \\(\\mu_h = \\frac{2}{h} \\frac{e^{h\\lambda} - 1}{e^{h\\lambda} + 1}\\) If the ODE on \\(\\widetilde{u}_n\\) is well-posed, the following statements are equivalent:\nThe method is of order \\(q\\) for linear problems; The modified vector field matches the initial one up to order \\(q\\), i.e. \\(\\frac{1}{h} \\ln\\bigl(r(h\\lambda)\\bigr) = \\lambda + \\mathcal{O}(h^q)\\); The \\(q\\)-th first derivatives of \\(\\widetilde{u}_h\\) at \\(t = 0\\) match those of the original equation. Investigate\nCheck that these three properties are indeed satisfied for the above examples. For a two-stage explicit method of order 2, find the order condition \\(b_1 + b_2 = 1\\) and \\(b_2 a_{12} = 1/2\\). Try to prove this proposition! Proof of the second property For the second property, a direct calculation yields $$ r(z) = 1 + z\\begin{pmatrix} b_{1} \u0026 b_{2} \\end{pmatrix} \\begin{pmatrix} 1 \u0026 0 \\\\ z a_{12} \u0026 1 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} = 1 + z(b_1 + b_2) + z^2 b_2 a_{12}, $$ from which we obtain the truncated series expansion $$ \\frac{1}{h}\\ln\\bigl(r(h\\lambda)\\bigr) = \\lambda(b_{1}+b_{2}) + h\\lambda b_{2}a_{12} - \\frac{h\\lambda}{2}(b_{1}+b_{2}) + \\mathcal{O}(h^2). $$ For the method to be of order 2, we need for all \\(\\lambda\\) $$ \\begin{cases} \\lambda(b_1 + b_2) = \\lambda, \\\\ \\lambda b_2 a_{12} - \\frac{\\lambda}{2}(b_1 + b_2) = 0, \\end{cases} $$ i.e. \\(b_1 + b_2 = 1\\) and \\(b_2 a_{12} = 1/2\\). The harmonic oscillator #In case of real data, i.e. \\(u \\in \\mathbb{R}^2\\), the previous multi-dimensional example involving \\(J = \\begin{pmatrix} 0 \u0026amp; -1 \\ 0 \u0026amp; 1 \\end{pmatrix}\\) may be identified with the complex problem \\(\\dot z = iz\\) with \\(z = u_1 + {\\rm i} u_2\\). Applying the previous identities with \\(\\lambda = {\\rm i}\\), we find\nExplicit Euler: \\(\\widetilde{\\lambda}_h = \\frac{1}{2h} \\log(1 + h^2) + \\frac{\\rm i}{h}\\arctan(h)\\) Implicit Euler: \\(\\widetilde{\\lambda}_h = \\frac{-1}{2h} \\log(1 + h^2) + \\frac{\\rm i}{h}\\arctan(h)\\), Midpoint: \\(\\widetilde{\\lambda}_h = \\frac{2{\\rm i}}{h} \\arctan(h/2)\\). For explicit Euler, \\(\\Re(\\widetilde{\\lambda}_h) \u0026gt; 0\\), therefore the method gains energy, meaning in this case that the module increases over time. For implicit Euler, \\(\\Re(\\widetilde{\\lambda}_h) \u0026lt; 0\\) so the method dissipates energy. For the midpoint method \\(\\Re(\\widetilde{\\lambda}_h) = 0\\), which indicates that energy is preserved.4 The method is said to be symplectic.\nWe can also find the corrected coefficients, respectively \\(\\mu_h = \\frac{1}{h}(e^{{\\rm i}h}-1)\\), \\(\\mu_h = \\frac{1}{h}(1 - e^{-{\\rm i}h})\\) and \\(\\mu_h = \\frac{2{\\rm i}}{h} \\tan(h/2)\\). Again, only the midpoint method generates an imaginary coefficient.\nThe multi-dimensional case #If \\(Z := h\\Lambda\\) is an operator of a \\(d\\)-dimensional space, a correct way to write the stability function would be $$ r(Z) = I_d + (I_d \\otimes b^{\\sf T}) \\left( I_d \\otimes I_s - Z \\otimes A \\right)^{-1} (Z \\otimes \\mathbb{1}_s) $$ where \\(\\otimes\\) is the Kronecker product, a useful tensor product for matrices.\nWhy the tensor product?\nGiven a Butcher tableau, the associated Runge-Kutta method is $$ \\begin{cases} k_1 = h \\Lambda \\left( u_n + a_{11} k_1 + \\dots + a_{1s} k_s \\right) \\\\ \\quad\\vdots \\\\ k_s = h \\Lambda \\left( u_n + a_{s1} k_1 + \\dots + a_{ss} k_s \\right) \\end{cases} $$ along with \\(u_{n+1} = u_n + b_1 k_1 + \u0026hellip; + b_s k_s\\). The vectors \\(k_i \\in \\mathbb{R}^d\\) may be collected in a tensor \\(\\mathbf{k} \\in \\mathbb{R}^d \\otimes \\mathbb{R}^s\\), and the fixed-point may then be written \\((I_d \\otimes I_s - h\\Lambda \\otimes A){\\bf k} = (h\\Lambda u_n) \\otimes \\mathbb{1}_s\\). The second part contracts the \\(\\mathbb{R}^s\\) part with \\(u_{n+1} = u_n + (I_d \\otimes b^{\\sf T}) {\\bf k}\\), where \\((I_d \\otimes b^{\\sf T}){\\bf k}\\) is identified from \\(\\mathbb{R}^d \\otimes \\mathbb{R}\\) to \\(\\mathbb{R}^d\\). This is cumbersome, so you\u0026rsquo;ll hopefully understand why I suck with the simple 1d notations. Just in case, here are the expressions for some common methods. $$ \\begin{aligned} \u0026amp;\\text{Exp. midpoint} \u0026amp;\u0026amp; r(Z) = \\operatorname{id} + Z \\left( \\operatorname{id} + {\\textstyle\\frac{1}{2}}Z \\right) . \\\\ \\\\ \u0026amp;\\text{Imp. midpoint} \u0026amp;\u0026amp; r(Z) = \\left( \\operatorname{id} - {\\textstyle\\frac{1}{2}} Z \\right)^{-1} (\\operatorname{id} + {\\textstyle\\frac{1}{2}} Z) \\\\ \\\\ \u0026amp; \\text{RK4} \u0026amp;\u0026amp; r(Z) = \\operatorname{id} + {\\textstyle\\frac{1}{6}}(K_1 + 2K_2 + 2K_3 + K_4 ) \\\\ \u0026amp;\u0026amp;\u0026amp; K_1 = Z,\\ K_2 = Z \\left( \\operatorname{id} + {\\textstyle\\frac{1}{2}} K_1 \\right),\\ \\\\ \u0026amp;\u0026amp;\u0026amp; K_3 = Z \\left( \\operatorname{id} + {\\textstyle\\frac{1}{2}} K_2 \\right), K_4 = Z \\left( \\operatorname{id} + K_3 \\right) \\end{aligned} $$\nReality check #The non-linear case #For a non-linear vector field, we must replace the exponential by the flow (morally, \\(\\varphi_h = e^{hf}\\)), and there are now additional terms in the power series, $$ \\begin{aligned} \\varphi_h \u0026amp;= \\operatorname{id} + hf + \\frac{h^2}{2}f\u0026rsquo;f + \\frac{h^3}{6}\\bigl[ f\u0026rsquo;\u0026rsquo;(f,f) + f\u0026rsquo;f\u0026rsquo;f \\bigr] \\\\ \u0026amp;+ \\frac{h^4}{4!} \\left[ f^{(3)}(f, f, f) + 3f\u0026rsquo;\u0026rsquo;(f, f\u0026rsquo;f) + f\u0026rsquo;f\u0026rsquo;\u0026rsquo;(f,f) + f\u0026rsquo;f\u0026rsquo;f\u0026rsquo;f \\right] + \\mathcal{O}(h^5) . \\end{aligned} $$ The computations become much more complex, and in general these series are purely formal, meaning that they diverge even for very small \\(h\\). Therefore the modified vector field \\(\\widetilde{f}_h\\) and the corrected vector field \\(g_h\\) can only be computed up to some power of \\(h\\), and the methods may be inaccurate for large time-steps.\nWe\u0026rsquo;re not supposed to know the flow #Of course these are only examples to explain the reasoning of the method and why it has a chance to work. In practice, we do not know \\(e^{h\\lambda}\\) (or its equivalent, the flow \\(\\varphi_h\\) or \\(e^{h\\Lambda}\\)), because if we did there would be no need for numerical methods. In the linear case, there is actually a lot of literature (which I\u0026rsquo;m not familiar with) on computing accurate high-order approximation of matrix exponentials. I don\u0026rsquo;t know if symplecticity is important for these applications.\nI won\u0026rsquo;t discuss infinite dimension, i.e. PDEs, because everything is always more complicated for PDEs.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nIn the multi-dimensional case \\(\\dot u = \\Lambda u\\), we may use the notation \\(\\ln(\\mathrm{id} + h\\Lambda) = \\sum\\limits_{n \\geq 1} \\frac{(-1)^{n+1}}{n}(h \\Lambda)^n\\), valid for \\(h |\\Lambda| \u0026lt; 1\\). For other cases, see for instance the Wikipedia page.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nSee e.g. E. Hairer, G. Wanner, Solving ordinary differential equations II. Stiff and Differential-Algebraic Problems (1996) \u0026ndash; Sec. IV.3\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nIn the generic non-linear case, the energy would be preserved up to a \\(\\mathcal{O}(h^2)\\) term.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"1 March 2024","permalink":"/blog/backward-error-analysis/02-linear-bea/","section":"Blog posts","summary":"","title":"Linear backward error analysis"},{"content":" There are two main areas in backward error analysis (b.e.a.), which are modified equations and modifying integrators. The first serve to study the properties of integrators, while the second improves the convergence of such integrators. Let\u0026rsquo;s have a look!\nModified equations #As mentioned previously, backward error analysis serves to find a so-called \u0026ldquo;modified\u0026rdquo; vector field for which the exact solution matches the numerical solution at discrete times. This is tentatively illustrated in the following diagram\nwhere \\(\\varphi_h\\) represents the exact integration of the ODE and \\(\\Phi_h\\) represents the application of a numerical method. The vector field \\(u \\mapsto f(u)\\) is the original vector field on which the numerical method is applied and \\(u \\mapsto \\widetilde{f}_h(u)\\) is the aforementioned modified vector field.\nAs an illustration1 here is a Lotka-Volterra problem \\[\\begin{cases}\\dot u_1 = u_1(2 - u_2), \\quad \u0026amp; u_1(0) = 2, \\\\ \\dot u_2 = u_2(u_1 - 1), \u0026amp; u_2(0) = 2 . \\end{cases} \\] simulated using the explicit Euler method, overlaid with the exact solutions of both the original problem and the modified problem, in phase-space.\nExact and numerical trajectories (with the Euler method) for the Lotka-Volterra problem \\(\\dot u = u(2-v),\\ \\dot v = v(u-1)\\) with initial condition \\(u(0) = v(0) = 2\\). Here the dashed lines are the exact solutions of (for now unspecified) modified differential equations. Notice that for each method, the line exactly2 matches the markers which denote the numerical solution.\nModifying integrators / Corrected equations #More recently, it has also been used to \u0026ldquo;correct\u0026rdquo; the vector field in simulations and improve numerical convergence. Once again, let me try to illustrate this with a diagram:\nUsing the notations of the first diagram, we want to find \\(g_h\\) such that \\(\\widetilde{g}_h = f\\), i.e. we want to somehow \u0026ldquo;invert\u0026rdquo; the backward error analysis. Unsurprisingly, this corrected field \\(g_h\\) depends on the time-step \\(h\\).\nConsidering again the Lotka-Volterra problem \\(\\dot u_1 = u_1(2-u_2)\\), \\(\\dot u_2 = u_2(u_1-1)\\), \\(u_1(0)= u_2(0) = 2\\) and the explicit Euler method, let\u0026rsquo;s look at the numerical solution of the corrected vector field and compare it with the exact solutions of both the original problem and the corrected problem.\nExact and numerical trajectories (with the Euler method) for the Lotka-Volterra problem \\(\\dot u = u(2-v),\\ \\dot v = v(u-1)\\) with initial condition \\(u(0) = v(0) = 2\\). This time, the numerical solution perfectly matches the exact solution at the discrete times! The error of the scheme is compensated by choosing the right corrected vector field.\nWhy should you care? #While there are many uses for both methods, here are two common use cases for each approach.\nModified equations\nfind the order of convergence of a numerical scheme study the long-time properties of integrators (such as energy preservation) Corrected equations:\nimprove the order of convergence of integrators (obviously) appears in machine learning of differential equations If this is all too abstract, you may read the next post with examples in the case of linear differential equations.\nThese illustrations are possible thanks to the Julia package B-Series. Thanks to the devs!\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nIn reality, the curves do not exactly match: the modified vector field \\(\\widetilde{f}_h\\) is computed as a truncated power series in \\(h\\), which induces a small error.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"28 February 2024","permalink":"/blog/backward-error-analysis/01-motivating-bea/","section":"Blog posts","summary":"","title":"Motivating backward error analysis"},{"content":" I want to discuss an interpretation of discrete approximations \\(u_n \\approx u(nh)\\) obtained from numerical schemes with time-step \\(h\\) as the continuous (exact) solution \\(t \\mapsto \\widetilde{u}_h(t)\\) of modified differential equations. This interpretation, called backward error analysis (BEA) is useful for long-time properties of numerical integrators, or even just their order of accuracy. Additionally, this relationship can be somehow \u0026ldquo;reversed\u0026rdquo; to improve numerical accuracy, which I\u0026rsquo;ll illustrate in this post.\nMy goal here is to present some ideas and to illustrate the results with some simple test cases, to share my initial wonder for BEA. I find that most of the literature quickly gets into the technical details of the how and why this works. There are elegant algebraic structures hidden here, with lots of applications and extensions and great maths\u0026mdash;all of which deserve this technicality! But it can also be a stumbling block for the understanding of the idea behind BEA. Readers who want to go further can peruse the following works:\nLecture notes of Ernst Hairer PDF Chartier, Hairer, Vilmart, \u0026ldquo;Numerical integrators based on modified differential equations\u0026rdquo; in Math. of Comp. (2007) DOI Chartier, Hairer, Vilmart, \u0026ldquo;Algebraic Structures of B-series\u0026rdquo; in FoCM (2010) DOI Hairer, Lubich, Wanner, Geometric Numerical Integration (2006) DOI ","date":null,"permalink":"/blog/backward-error-analysis/","section":"Blog posts","summary":"","title":"A gentle introduction to backward error analysis"},{"content":"","date":null,"permalink":"/categories/","section":"Categories","summary":"","title":"Categories"},{"content":"","date":null,"permalink":"/categories/enseignement/","section":"Categories","summary":"","title":"Enseignement"},{"content":"","date":null,"permalink":"/tags/licence/","section":"Tags","summary":"","title":"Licence"},{"content":"","date":null,"permalink":"/tags/ludique/","section":"Tags","summary":"","title":"Ludique"},{"content":"","date":null,"permalink":"/tags/","section":"Tags","summary":"","title":"Tags"},{"content":" Ce sujet PDF est inspiré d’une superbe vidéo de Jacob Yatsko dans laquelle les nombres de Fibonacci modulo \\(p \\in \\mathbb{N}^*\\) sont placés sur un cercle. À partir d’un certain rang (qui dépend de \\(p\\)), la suite est périodique; ce rang est appelé période de Pisano. L’objectif du TP est de reproduire cette visualisation sur le cercle avec Scilab.\nÉtant donné que le sujet s’adresse aux élèves en fin de première année de formation GEII à l’IUT, la notion de modulo n’est pas supposée connue, donc elle est présentée rapidement. En accord avec l’esprit du cours Outils Logiciels, les questions mélangent raisonnements mathématiques et programmation. Notamment, on se sert de la programmation pour calculer la période de Pisano. Ce sujet permet en outre d’introduire de la notion d’erreur d’arrondis. En effet, comme les termes de la suite de Fibonacci croissent de manière exponentielle, on ne peut pas se contenter de les calculer puis de les prendre modulo \\(p\\). Il faut faire tous les calculs modulo \\(p\\).\nLes questions primordiales sont indiquées avec un cœur et les questions standard avec un triangle. Les élèves qui souhaitent approfondir le sujet et leurs connaissances mathématiques (ou simplement améliorer leur note) peuvent répondre aux questions indiquées par un symbole de pique. De cette manière, les connaissances attendues par l’étudiant sont rendues explicites.\nIl est à noter que ce sujet a été pensé comme un mini-projet en temps libre sur plusieurs semaines, et donc certaines questions sont difficiles. Les élèves sont encouragé-e-s à soliciter les enseignant-e-s pour se débloquer.\n","date":"11 May 2022","permalink":"/blog/tp-pisano/","section":"Blog posts","summary":"","title":"TP: Visualisation de la période de Pisano"},{"content":"I am a teaching assistant (Maître de Conférences) in Lens, in northern France. Half of my time is spent teaching young programmers at the IUT in the Computer Science department. The other half is spent doing research in the Laboratoire de Mathématiques de Lens.\nBefore joining Lens, I was a post-doc in the Inria team Macaron (previously TONUS) and IRMA in Strasbourg, working with C. Courtès, E. Franck, M. Kraus and L. Navoret. Before that, I was a graduate assistant at Ensimag as a member of the Laboratoire Jean Kuntzmann in Grenoble. I completed my PhD in December 2021 in Rennes under the supervision of P. Chartier and M. Lemou.\nMy research focuses on multi-scale and geometric methods in a numerical context. More specifically, I study the properties of asymptotic expansions and use them to obtain better numerical convergence in stiff problems. During my PhD, I worked on relaxation problems such as the linear Boltzmann equation, and more recently I worked on the Bloch equation. For my post-doc, I study the properties of geometric machine learning when reconstructing vector fields based on trajectories.\n","date":null,"permalink":"/about/","section":"Website of Léopold Trémant","summary":"","title":"About me"},{"content":" Journals Brigitte Bidégaray-Fesquet, Clément Jourdana, LT, \u0026ldquo;Multi-frequency averaging and uniform accuracy towards numerical approximations for a Bloch model\u0026rdquo; (2023). To appear in Communications in Mathematical Sciences. PDF HAL Philippe Chartier, Mohammed Lemou, Florian Méhats, LT, \u0026ldquo;Averaging in a Nutshell\u0026rdquo; (2024). To be submitted. PDF Philippe Chartier, Mohammed Lemou, LT, \u0026ldquo;A uniformly accurate numerical method for a class of dissipative systems\u0026rdquo; (2021). In Mathematics of Computation. PDF DOI Thesis LT, \u0026ldquo;Méthodes d’analyse asymptotique et d’approximation numérique\u0026rdquo; (2021). PhD thesis. PDF Slides ","date":null,"permalink":"/work/","section":"Website of Léopold Trémant","summary":"","title":"Publications"}]